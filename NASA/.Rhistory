knitr::opts_chunk$set(echo = TRUE)
if (!require("sf", character.only = TRUE)) {
install.packages("sf")
}
if (!require("readxl", character.only = TRUE)) {
install.packages("readxl")
}
if (!require("writexl", character.only = TRUE)) {
install.packages("writexl")
}
if (!require("jsonlite", character.only = TRUE)) {
install.packages("jsonlite")
}
library("sf")
library("readxl")
library("writexl")
library("jsonlite")
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- DF_plume[, -which(names(DF_plume) == "style")]
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
View(DF_plume)
DAAC_list <- sapply(DF_plume["DAAC Scene Numbers"], function(x) paste(x, collapse = ","))
sapply(DF_plume["DAAC Scene Numbers"], function(x) print(x))
sapply(DF_plume["DAAC Scene Numbers"], function(x) print(unlist(x)))
View(DF_plume)
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DAAC_list <- sapply(DF_plume["DAAC Scene Numbers"], combine_elements)
combine_elements <- function(lst) {
if (is.list(lst)) {
paste(lst, collapse = ",")
} else {
lst
}
}
DAAC_list <- sapply(DF_plume["DAAC Scene Numbers"], combine_elements)
DAAC_list <- sapply(DF_plume["DAAC Scene Numbers"], combine_elements)
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
combine_elements <- function(lst) {
if (is.list(lst)) {
paste(lst, collapse = ",")
} else {
lst
}
}
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DAAC_list <- sapply(DF_plume["DAAC Scene Numbers"], combine_elements)
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
convert_to_string <- function(element) {
if (is.vector(element)) {
paste(element, collapse = ",")
} else {
element
}
}
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DAAC_list <- lapply(DF_plume["DAAC Scene Numbers"], convert_to_string)
View(DAAC_list)
View(DAAC_list)
DAAC_list <- DF_plume["DAAC Scene Numbers"]
View(DAAC_list)
DF_plume["Test"] <- DF_plume["DAAC Scene Numbers"]
View(DF_plume)
write_xlsx(DF_plume, "./test.xlsx")
paste(DF_plume["DAAC Scene Numbers"], collapse = ",")
lapply(DF_plume["DAAC Scene Numbers"] x print(x))
lapply(DF_plume["DAAC Scene Numbers"], x print(x))
lapply(DF_plume["DAAC Scene Numbers"] x, print(x))
lapply(DF_plume["DAAC Scene Numbers"], function(x) print(x))
lapply(DF_plume["DAAC Scene Numbers"], function(x) print(paste(x, collapse = ",")))
lapply(DF_plume["DAAC Scene Numbers"], 1, function(x) print(paste(x, collapse = ",")))
apply(DF_plume["DAAC Scene Numbers"], 1, function(x) print(paste(x, collapse = ",")))
gsub("c", "", DF_plume["DAAC Scene Numbers"])
gsub("[c()]"", "", DF_plume["DAAC Scene Numbers"])
gsub("[c()], "", DF_plume["DAAC Scene Numbers"])
gsub("[c()]", "", DF_plume["DAAC Scene Numbers"])
DF_plume["DAAC Scene Numbers"]
DF_plume["DAAC Scene Numbers"][1793]
DF_plume["DAAC Scene Numbers"][1793 ,]
DF_plume["DAAC Scene Numbers"][, 1793 ,]
DF_plume["DAAC Scene Numbers"][, 1793]
DF_plume["DAAC Scene Numbers"][1793]
DF_plume["DAAC Scene Numbers"][1]
DF_plume["DAAC Scene Numbers"][[1]]
DF_plume["DAAC Scene Numbers"][[2]]
DF_plume["DAAC Scene Numbers"][[1]]
DF_plume["DAAC Scene Numbers"][[1]][1]
lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) print(paste(x, collapse = ",")))
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) print(paste(x, collapse = ",")))
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
TEST <- lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
View(TEST)
lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
lapply(DF_plume["DAAC Scene Numbers"], function(x) paste(x, collapse = ","))
lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
DF_plume["DAAC Scene Numbers"][[1]]
View(DF_plume)
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
View(DF_plume)
TEST <- lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
View(TEST)
DF_plume["DAAC Scene Numbers"] <- lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ","))
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- unlist(lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ",")))
View(DF_plume)
DF_plume["Scene FIDs"] <- unlist(lapply(DF_plume["Scene FIDs"][[1]], function(x) paste(x, collapse = ",")))
View(DF_plume)
DF_plume["DAAC Scene Numbers"] <- DF_plume["DAAC Scene Numbers"][[1]]
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- DF_plume["DAAC Scene Numbers"][[1]]
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- unlist(DF_plume["DAAC Scene Numbers"][[1]])
knitr::opts_chunk$set(echo = TRUE)
if (!require("sf", character.only = TRUE)) {
install.packages("sf")
}
if (!require("readxl", character.only = TRUE)) {
install.packages("readxl")
}
if (!require("writexl", character.only = TRUE)) {
install.packages("writexl")
}
if (!require("jsonlite", character.only = TRUE)) {
install.packages("jsonlite")
}
library("sf")
library("readxl")
library("writexl")
library("jsonlite")
rm(list=ls())
## Input Excel File Path ##
excel_file_path <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Test Data/TD9_DRAFT_Targeting-NM_WellsForCarbonMapper_2023-11-08.xlsx"
## Output Folder ##
output_folder <- "C:/Users/TRichman.ERG/Tyler/Tool Development/Plume Data Extraction/Output"
## Input Column Names for Coordinates ##
x_field = "LONGITUDE"
y_field ="LATITUDE"
## Input Buffer Distance in Miles ##
bufferDist_mi = 0.5
opt <- options(show.error.messages = TRUE)
on.exit(options(opt))
## URL of Carbon Mapper Plume Data ##
NASAJSON_path = "https://earth.jpl.nasa.gov/emit-mmgis-lb/Missions/EMIT/Layers/coverage/combined_plume_metadata.json"
## Create a Date Frame from Records with non-NA Coordinates in Excel File ##
DF <- read_excel(excel_file_path)
DF[["UID"]] <- seq_len(nrow(DF))
DF <- DF[, c("UID", setdiff(names(DF), "UID"))]
## Remove Facilities from DataFrame that do no have Coordinates ##
if (any(is.na(DF[[x_field]])) | any(is.na(DF[[y_field]]))){
DF_noCoord <- DF[is.na(DF[[x_field]]) | is.na(DF[[y_field]]),]
DF <- DF[!(DF[["UID"]] %in% DF_noCoord[["UID"]]),]
}
## Import and Process NASA Data ##
DF_plume <- fromJSON(NASAJSON_path)[["features"]][["properties"]]
DF_plume <- unique(DF_plume[, -which(names(DF_plume) == "style")])
DF_plume["DAAC Scene Numbers"] <- unlist(lapply(DF_plume["DAAC Scene Numbers"][[1]], function(x) paste(x, collapse = ",")))
DF_plume["Scene FIDs"] <- unlist(lapply(DF_plume["Scene FIDs"][[1]], function(x) paste(x, collapse = ",")))
DF_plume["x"] <- DF_plume["Longitude of max concentration"]
DF_plume["y"] <- DF_plume["Latitude of max concentration"]
## Create Spatial Data Frames (SFs) for Facilities and Plumes and Transform to NAD 1983 Equidistant Conic contiguous USA CRS ##
DF["x"] <- DF[x_field]
DF["y"] <- DF[y_field]
SF_facility <- st_as_sf(
DF,
coords = c("x", "y")
)
SF_facility <- st_set_crs(SF_facility, 4269) %>% st_transform("ESRI:102005")
SF_plume <- st_as_sf(
DF_plume,
coords = c("x", "y")
)
SF_plume <- st_set_crs(SF_plume, 4269) %>% st_transform("ESRI:102005")
## Create a Buffer with Specified Distance from Facility SF ##
SF_facility_Buffer <- st_buffer(
SF_facility,
dist = units::set_units(bufferDist_mi,"mi")
)
## Spatial Join Facility Buffer SF with Plume SF ##
SF_joined <- st_join(
SF_facility_Buffer,
SF_plume,
join = st_intersects
)
## Transform SF Joined back into Standard DF ##
DF_joined <-  as.data.frame(SF_joined)
DF_joined <- DF_joined[, -which(names(DF_joined) == "geometry")]
## Remove Rows without a match ##
DF_joined <- DF_joined[!is.na(DF_joined[["Plume ID"]]) ,]
## Create String Representing the Buffer Distance ##
buffer_str = gsub("\\.", "p", as.character(bufferDist_mi))
## Create String Representing Today's Date ##
today_date <- Sys.Date()
formatted_date <- format(today_date, "%Y%m%d")
## Process Final Table ##
DF_FINAL <- DF_joined
## Calculate distance between the two points ##
DF_FINAL[["geom"]] <- paste0(
"LINESTRING (",
paste(DF_FINAL[[x_field]], DF_FINAL[[y_field]]),
", ",
paste(DF_FINAL[["Longitude of max concentration"]], DF_FINAL[["Latitude of max concentration"]]),
")"
)
DF_FINAL <- st_as_sf(DF_FINAL, wkt = "geom")
DF_FINAL <- st_set_crs(DF_FINAL, 4269) %>% st_transform("ESRI:102005")
DF_FINAL[["Distance_mi"]] <- st_length(DF_FINAL)
DF_FINAL[["Distance_mi"]] <- as.numeric(sub("\\[m\\]", "", DF_FINAL[["Distance_mi"]])) / 1609.344
DF_FINAL <-  as.data.frame(DF_FINAL)
DF_FINAL <- DF_FINAL[, -which(names(DF_FINAL) == "geom")]
## Output Spatial Join and Facilities with Missing Coordinates to Excel ##
out_xlsx_name = paste0(
gsub(".xlsx", "_NASAPlumes",basename(excel_file_path)),
"_",
buffer_str,
"mi_",
formatted_date,
".xlsx"
)
write_xlsx(
DF_FINAL,
file.path(output_folder, out_xlsx_name)
)
